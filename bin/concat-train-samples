#!/usr/bin/env python
# Concatenate samples from a bunch of subsets of training set

import glob
import os
from pathlib import Path
import typer
import xarray as xr

app = typer.Typer()

@app.command()
def main(root: Path, num_samples: int = 3):
    num_subsets = 5

    # group sample files into tuples with one from each subset
    grouped_pred_files = list(zip(*[ glob.glob(os.path.join(root, f"train-{i}/*.nc")) for i in range(0,num_subsets) ]))
    # there should be 3 sets of complete subset groupings
    assert(len(grouped_pred_files) == num_samples)

    for pred_files in grouped_pred_files:
        print(f"Concat {pred_files}")

        # take a bit of the random id in each sample file's name
        random_ids = [fn[-25:-20] for fn in pred_files]
        # join those partial random ids together for the output filepath in the train directory (rather than one of the subset train dirs)
        output_filepath = os.path.join(root, f"train/predictions-{'-'.join(random_ids)}.nc")
        print(f"save to {output_filepath}")
        os.makedirs(os.path.dirname(output_filepath), exist_ok=True)
        xr.concat([xr.open_dataset(f) for f in pred_files], dim="time").to_netcdf(output_filepath)


if __name__ == "__main__":
    app()