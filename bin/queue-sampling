#!/usr/bin/env python
# setup jobs for sampling from a model

import os
import subprocess
import sys

import typer

app = typer.Typer()

def sample_cmd(sde, dataset, epoch, samples_per_job, workdir):
  sample_basecmd = ["python", f"predict.py"]

  sample_opts = {
    "--epoch": str(epoch),
    "--num-samples": str(samples_per_job),
    "--dataset": dataset,
    "--sde": sde,
  }

  return sample_basecmd + [arg for item in sample_opts.items() for arg in item] + [workdir]

def queue_cmd(depends_on, sampling_jobs, sampling_duration):
  queue_basecmd = ["lbatch"]

  queue_opts = {
    "-g": "1",
    "-m": "16",
    "-q": "gpu,cnu",
    "-t": str(sampling_duration),
    "--condaenv": "cuda-downscaling",
    "--array": f"1-{sampling_jobs}"
  }
  if depends_on is not None:
    queue_opts["-d"] = str(depends_on)

  return queue_basecmd + [arg for item in queue_opts.items() for arg in item]

@app.command()
def main(model_run_id: str, cpm_dataset: str, gcm_dataset: str, sde: str, epoch: int = 100, depends_on: int = None):

  sampling_jobs=3
  samples_per_job=1
  sampling_duration=18*samples_per_job

  workdir=f"{os.getenv('DERIVED_DATA')}/workdirs/score-sde/${sde}/xarray_cncsnpp_continuous/${model_run_id}"

  shared_queue_cmd = queue_cmd(depends_on, sampling_jobs, sampling_duration)

  # sample CPM
  full_cmd = shared_queue_cmd + ["--"] + sample_cmd(sde, cpm_dataset, epoch, samples_per_job, workdir)
  print(" ".join(full_cmd), file=sys.stderr)
  output = subprocess.run(full_cmd, capture_output=True)
  print(output.stdout.decode("utf8"))
  print(output.stderr.decode("utf8"), file=sys.stderr)

  # sample GCM
  full_cmd = shared_queue_cmd + ["--"] + sample_cmd(sde, gcm_dataset, epoch, samples_per_job, workdir)
  print(" ".join(full_cmd), file=sys.stderr)
  output = subprocess.run(full_cmd, capture_output=True)
  print(output.stdout.decode("utf8"))
  print(output.stderr.decode("utf8"), file=sys.stderr)

if __name__ == "__main__":
    app()