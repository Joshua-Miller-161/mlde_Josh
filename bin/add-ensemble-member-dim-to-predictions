#!/usr/bin/env python
# make sure all datasets have ensemble member and add default to any that don't

import glob
import logging
import os
import xarray as xr

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format="%(levelname)s %(asctime)s: %(message)s")

DEFAULT_ENSEMBLE_MEMBER = "01"


def fix_file(nc_filepath):
    logger.info(f"Working on {nc_filepath}")
    ds = xr.open_dataset(nc_filepath)

    if "ensemble_member" in ds.dims:
        logger.info(f"Already has ensemble member: {nc_filepath}")
        ds.close()
        return

    logger.info(f"Fixing {nc_filepath}")
    ds = ds.load()
    ds.close()
    ds = ds.expand_dims(dict(ensemble_member=[DEFAULT_ENSEMBLE_MEMBER]))

    dirpath, filename = os.path.split(nc_filepath)
    new_filepath = os.path.join(dirpath, "01", filename)
    os.makedirs(os.path.dirname(new_filepath), exist_ok=True)

    ds.to_netcdf(new_filepath)


def main():
    models_glob = os.path.join(
        os.getenv("DERIVED_DATA"),
        "workdirs",
        "score-sde",
        "*",  # sde
        "xarray_cncsnpp_continuous",
        "*",  # model name
    )
    model_dirs = glob.glob(models_glob)
    for model_dir in model_dirs:
        if os.path.basename(model_dir) == "archive":
            continue

        samples_glob = os.path.join(
            model_dir,
            "samples",
            "*",  # checkpoint
            "*",  # dataset
            "*",  # input_xfm
            "*",  # split
            "predictions-*.nc",
        )
        sample_filepaths = glob.glob(samples_glob)
        for sample_filepath in sample_filepaths:
            fix_file(sample_filepath)


if __name__ == "__main__":
    main()
