#!/usr/bin/env python
# make sure all datasets have ensemble member and add default to any that don't

import glob
import logging
import os
import xarray as xr

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format="%(levelname)s %(asctime)s: %(message)s")

DEFAULT_ENSEMBLE_MEMBER = "01"


def fix_file(nc_filepath):
    logger.info(f"Working on {nc_filepath}")
    ds = xr.open_dataset(nc_filepath)

    if "ensemble_member" in ds.dims:
        logger.info(f"Already has ensemble member: {nc_filepath}")
        ds.close()
        return

    logger.info(f"Fixing {nc_filepath}")
    ds = ds.load()
    ds.close()
    ds = ds.expand_dims(dict(ensemble_member=[DEFAULT_ENSEMBLE_MEMBER]))

    dirpath, filename = os.path.split(nc_filepath)
    new_filepath = os.path.join(dirpath, "01", filename)
    os.makedirs(os.path.dirname(new_filepath), exist_ok=True)

    ds.to_netcdf(new_filepath)

    ds = xr.open_dataset(new_filepath)
    assert list(ds["pred_pr"].dims) == [
        "ensemble_member",
        "time",
        "grid_latitude",
        "grid_longitude",
    ], list(ds["pred_pr"].dims)
    assert ds["pred_pr"].shape[0] == 1
    assert ds["pred_pr"].shape[1] > 0
    assert ds["pred_pr"].shape[2] == 64
    assert ds["pred_pr"].shape[3] == 64
    assert ds["pred_pr"].isnull().sum().values.item() == 0
    logger.info(f"Removing original prediction file: {nc_filepath}")
    os.remove(nc_filepath)


def main():
    diff_models_glob = os.path.join(
        os.getenv("DERIVED_DATA"),
        "workdirs",
        "score-sde",
        "*",  # sde
        "xarray_cncsnpp_continuous",
        "*",  # model name
    )

    unet_models_glob = os.path.join(
        os.getenv("DERIVED_DATA"),
        "workdirs",
        "u-net",
        "*",  # model name
    )

    id_linpr_models_glob = os.path.join(
        os.getenv("DERIVED_DATA"),
        "id-linpr",  # model name
    )

    model_dirs = (
        glob.glob(diff_models_glob)
        + glob.glob(unet_models_glob)
        + glob.glob(id_linpr_models_glob)
    )
    for model_dir in model_dirs:
        if os.path.basename(model_dir) == "archive":
            continue

        samples_glob = os.path.join(
            model_dir,
            "samples",
            "*",  # checkpoint
            "*",  # dataset
            "*",  # input_xfm
            "*",  # split
            "predictions-*.nc",
        )
        sample_filepaths = glob.glob(samples_glob)
        for sample_filepath in sample_filepaths:
            fix_file(sample_filepath)


if __name__ == "__main__":
    main()
